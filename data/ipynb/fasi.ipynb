{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fasi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DsPh9b89KwV"
      },
      "source": [
        "# CNN Fashion Style Classification Modeling\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItbWQfsf9XCW"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnBpTVOD6B7m"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.applications import vgg16\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Model, Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvVr-sDZ9hLU"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adtok_yz6ZE6",
        "outputId": "458f1f5f-c573-48d6-b8de-34cd5624cd17"
      },
      "source": [
        "tr = '/content/drive/MyDrive/style/tr'\n",
        "val = '/content/drive/MyDrive/style/val'\n",
        "\n",
        "# 클래스 리스트 선언\n",
        "class_list = ['street', 'simple', 'classic', 'work', 'unique', 'sexy', 'girlish']\n",
        "\n",
        "tr = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    tr,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=class_list,\n",
        "    seed=6,\n",
        ")\n",
        "\n",
        "val = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    val,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=class_list,\n",
        "    seed=6,\n",
        ")\n",
        "\n",
        "tr, val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3354 files belonging to 7 classes.\n",
            "Found 838 files belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<BatchDataset shapes: ((None, 256, 256, 3), (None, 7)), types: (tf.float32, tf.float32)>,\n",
              " <BatchDataset shapes: ((None, 256, 256, 3), (None, 7)), types: (tf.float32, tf.float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90I68cTx_zvk"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dcVTjyEBtZw",
        "outputId": "cfc39971-73d4-4288-9316-7903d39a51d7"
      },
      "source": [
        "# 간단한 CNN 신경망 구축\n",
        "model1 = Sequential()\n",
        "model1.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "model1.add(MaxPooling2D((2, 2)))\n",
        "model1.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model1.add(MaxPooling2D((2, 2)))\n",
        "model1.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(64, activation='relu'))\n",
        "model1.add(Dense(7, activation='softmax'))\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 125, 125, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 60, 60, 64)        36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 230400)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                14745664  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 14,802,439\n",
            "Trainable params: 14,802,439\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_cjV2uyCJgF",
        "outputId": "ede1ba64-dfe6-44ef-94fe-f1fc675d37bf"
      },
      "source": [
        "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model1.fit(tr, validation_data=val, epochs=5)\n",
        "\n",
        "model1.evaluate(val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "105/105 [==============================] - 586s 5s/step - loss: 99.1621 - accuracy: 0.1586 - val_loss: 1.9354 - val_accuracy: 0.2005\n",
            "Epoch 2/5\n",
            "105/105 [==============================] - 31s 281ms/step - loss: 1.7764 - accuracy: 0.2984 - val_loss: 1.9811 - val_accuracy: 0.1874\n",
            "Epoch 3/5\n",
            "105/105 [==============================] - 31s 283ms/step - loss: 1.3210 - accuracy: 0.5030 - val_loss: 2.3484 - val_accuracy: 0.1933\n",
            "Epoch 4/5\n",
            "105/105 [==============================] - 31s 280ms/step - loss: 0.9013 - accuracy: 0.6694 - val_loss: 3.5334 - val_accuracy: 0.1802\n",
            "Epoch 5/5\n",
            "105/105 [==============================] - 31s 281ms/step - loss: 0.6528 - accuracy: 0.7645 - val_loss: 3.8732 - val_accuracy: 0.1706\n",
            "27/27 [==============================] - 6s 152ms/step - loss: 3.8732 - accuracy: 0.1706\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.8732028007507324, 0.1706443876028061]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XcZ17qnBEMk"
      },
      "source": [
        "## Model 개선"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkPEy1PmITAZ",
        "outputId": "a5d4a1bf-a1cd-45ba-c1ee-7cc5d41cc279"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                    activation ='relu', input_shape = (256, 256, 3)))\n",
        "model2.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                    activation ='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                    activation ='relu'))\n",
        "model2.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                    activation ='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
        "                    activation ='relu'))\n",
        "model2.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
        "                    activation ='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(1024, activation = \"relu\"))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(512, activation = \"relu\"))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(7, activation = \"softmax\"))\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 256, 256, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 256, 256, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 128, 128, 64)      18496     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 64, 64, 86)        49622     \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 64, 64, 86)        66650     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 32, 32, 86)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 86)        344       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32, 32, 86)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 88064)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              90178560  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 7)                 3591      \n",
            "=================================================================\n",
            "Total params: 90,889,519\n",
            "Trainable params: 90,889,155\n",
            "Non-trainable params: 364\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcWBCUQyIwl1",
        "outputId": "6a70eb89-40bd-4180-88dc-55d3606006c0"
      },
      "source": [
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model2.fit(tr, validation_data=val, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "105/105 [==============================] - 47s 423ms/step - loss: 1.7905 - accuracy: 0.3196 - val_loss: 2.5823 - val_accuracy: 0.2196\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 46s 419ms/step - loss: 1.6277 - accuracy: 0.3778 - val_loss: 1.9698 - val_accuracy: 0.2446\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 46s 421ms/step - loss: 1.4714 - accuracy: 0.4499 - val_loss: 1.9101 - val_accuracy: 0.2506\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 46s 420ms/step - loss: 1.3013 - accuracy: 0.5176 - val_loss: 2.0795 - val_accuracy: 0.2780\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 45s 415ms/step - loss: 1.0184 - accuracy: 0.6237 - val_loss: 2.4519 - val_accuracy: 0.2840\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 45s 418ms/step - loss: 0.8468 - accuracy: 0.6968 - val_loss: 2.4766 - val_accuracy: 0.2768\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 46s 422ms/step - loss: 0.7311 - accuracy: 0.7394 - val_loss: 2.7377 - val_accuracy: 0.2900\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 46s 422ms/step - loss: 0.5902 - accuracy: 0.7928 - val_loss: 2.7308 - val_accuracy: 0.2721\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 45s 417ms/step - loss: 0.4384 - accuracy: 0.8456 - val_loss: 3.4322 - val_accuracy: 0.2637\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 46s 418ms/step - loss: 0.3729 - accuracy: 0.8739 - val_loss: 2.8680 - val_accuracy: 0.3007\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d8196b350>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1queVl1ItFe"
      },
      "source": [
        "## ResNet Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITZ0w-O-ikJn",
        "outputId": "0947dab9-a00e-4068-bcce-589682cfd60e"
      },
      "source": [
        "# Fully Connected layer 부분을 제거하는 역할\n",
        "resnet = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "# ResNet50 레이어의 파라미터를 학습하지 않도록 설정\n",
        "# 역전파를 통해 오차 정보가 전파 되더라도 파라미터가 업데이트되지 않는다.\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Fully connected layer 추가\n",
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(7, activation='sigmoid')(x)\n",
        "model3 = Model(resnet.input, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdxJIz46Kein",
        "outputId": "1c70c37b-da2b-46fd-ba1d-1ac9d31a90e3"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 7)            7175        dense_5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 25,693,063\n",
            "Trainable params: 2,105,351\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hun0oo45ikJo",
        "outputId": "637ff5ad-0074-478b-e0d5-4bc282aea24b"
      },
      "source": [
        "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model3.fit(tr, validation_data=val, epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "105/105 [==============================] - 46s 375ms/step - loss: 2.2210 - accuracy: 0.3408 - val_loss: 1.6776 - val_accuracy: 0.3198\n",
            "Epoch 2/20\n",
            "105/105 [==============================] - 38s 344ms/step - loss: 1.2494 - accuracy: 0.5277 - val_loss: 1.6757 - val_accuracy: 0.3544\n",
            "Epoch 3/20\n",
            "105/105 [==============================] - 37s 341ms/step - loss: 1.1146 - accuracy: 0.5817 - val_loss: 1.7384 - val_accuracy: 0.3735\n",
            "Epoch 4/20\n",
            "105/105 [==============================] - 38s 342ms/step - loss: 1.0167 - accuracy: 0.6187 - val_loss: 1.6563 - val_accuracy: 0.3735\n",
            "Epoch 5/20\n",
            "105/105 [==============================] - 37s 340ms/step - loss: 0.9401 - accuracy: 0.6452 - val_loss: 1.6776 - val_accuracy: 0.3819\n",
            "Epoch 6/20\n",
            "105/105 [==============================] - 38s 343ms/step - loss: 0.8510 - accuracy: 0.6878 - val_loss: 1.7892 - val_accuracy: 0.3580\n",
            "Epoch 7/20\n",
            "105/105 [==============================] - 38s 346ms/step - loss: 0.7629 - accuracy: 0.7287 - val_loss: 1.7751 - val_accuracy: 0.3926\n",
            "Epoch 8/20\n",
            "105/105 [==============================] - 38s 343ms/step - loss: 0.7210 - accuracy: 0.7385 - val_loss: 1.9225 - val_accuracy: 0.3663\n",
            "Epoch 9/20\n",
            "105/105 [==============================] - 38s 342ms/step - loss: 0.6344 - accuracy: 0.7713 - val_loss: 2.2290 - val_accuracy: 0.2995\n",
            "Epoch 10/20\n",
            "105/105 [==============================] - 38s 345ms/step - loss: 0.6084 - accuracy: 0.7767 - val_loss: 1.9812 - val_accuracy: 0.3890\n",
            "Epoch 11/20\n",
            "105/105 [==============================] - 38s 344ms/step - loss: 0.5343 - accuracy: 0.8151 - val_loss: 2.0343 - val_accuracy: 0.3962\n",
            "Epoch 12/20\n",
            "105/105 [==============================] - 38s 343ms/step - loss: 0.4851 - accuracy: 0.8277 - val_loss: 2.4881 - val_accuracy: 0.3425\n",
            "Epoch 13/20\n",
            "105/105 [==============================] - 38s 346ms/step - loss: 0.3974 - accuracy: 0.8715 - val_loss: 2.3355 - val_accuracy: 0.3687\n",
            "Epoch 14/20\n",
            "105/105 [==============================] - 38s 344ms/step - loss: 0.3552 - accuracy: 0.8882 - val_loss: 2.3268 - val_accuracy: 0.3699\n",
            "Epoch 15/20\n",
            "105/105 [==============================] - 38s 347ms/step - loss: 0.2798 - accuracy: 0.9198 - val_loss: 2.2989 - val_accuracy: 0.3783\n",
            "Epoch 16/20\n",
            "105/105 [==============================] - 38s 347ms/step - loss: 0.2640 - accuracy: 0.9234 - val_loss: 2.6399 - val_accuracy: 0.3162\n",
            "Epoch 17/20\n",
            "105/105 [==============================] - 38s 347ms/step - loss: 0.2391 - accuracy: 0.9338 - val_loss: 2.4771 - val_accuracy: 0.3926\n",
            "Epoch 18/20\n",
            "105/105 [==============================] - 38s 348ms/step - loss: 0.2017 - accuracy: 0.9466 - val_loss: 2.7124 - val_accuracy: 0.3508\n",
            "Epoch 19/20\n",
            "105/105 [==============================] - 38s 348ms/step - loss: 0.1735 - accuracy: 0.9550 - val_loss: 3.0435 - val_accuracy: 0.3258\n",
            "Epoch 20/20\n",
            "105/105 [==============================] - 38s 349ms/step - loss: 0.1267 - accuracy: 0.9744 - val_loss: 2.9719 - val_accuracy: 0.3508\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d08ed2b50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chiVLYtVOQu9"
      },
      "source": [
        "## 데이터 추가 수집 및 하이퍼파라미터 튜닝"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EHEKh82OZC2",
        "outputId": "ed85f1f2-7404-46f1-ebbc-3e8beafde48e"
      },
      "source": [
        "tr = '/content/drive/MyDrive/style/tr'\n",
        "val = '/content/drive/MyDrive/style/val'\n",
        "\n",
        "tr_for_man = '/content/drive/MyDrive/style-for-man/tr'\n",
        "val_for_man = '/content/drive/MyDrive/style-for-man/val'\n",
        "\n",
        "# 클래스 리스트 선언\n",
        "class_list = ['street', 'simple', 'classic', 'work', 'unique', 'sexy', 'girlish']\n",
        "class_list_for_man = ['street', 'simple', 'classic', 'work', 'unique']\n",
        "\n",
        "# woman\n",
        "tr = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    tr,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=class_list,\n",
        "    seed=6,\n",
        ")\n",
        "\n",
        "val = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    val,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=class_list,\n",
        "    seed=6,\n",
        ")\n",
        "\n",
        "# man\n",
        "tr_for_man = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    tr_for_man,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=class_list_for_man,\n",
        "    seed=6,\n",
        ")\n",
        "\n",
        "val_for_man = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    val_for_man,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=class_list_for_man,\n",
        "    seed=6,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6575 files belonging to 7 classes.\n",
            "Found 1638 files belonging to 7 classes.\n",
            "Found 4792 files belonging to 5 classes.\n",
            "Found 1195 files belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh5nsCsLh0Eo",
        "outputId": "7fe3ec9a-cb1f-401e-f2da-bf49f0a0729f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtJ5W3QYhfVD"
      },
      "source": [
        "# Fully Connected layer 부분을 제거하는 역할\n",
        "resnet = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "# ResNet50 레이어의 파라미터를 학습하지 않도록 설정\n",
        "# 역전파를 통해 오차 정보가 전파 되더라도 파라미터가 업데이트되지 않는다.\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Fully connected layer 추가\n",
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(7, activation='sigmoid')(x)\n",
        "model = Model(resnet.input, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3cC_mikOyv9",
        "outputId": "122a94e1-62c1-4ebc-e17c-a34be2c9ee73"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(tr, validation_data=val, epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "206/206 [==============================] - 2064s 10s/step - loss: 1.6968 - accuracy: 0.4268 - val_loss: 1.5101 - val_accuracy: 0.4261\n",
            "Epoch 2/50\n",
            "206/206 [==============================] - 69s 329ms/step - loss: 1.2515 - accuracy: 0.5227 - val_loss: 1.4183 - val_accuracy: 0.4670\n",
            "Epoch 3/50\n",
            "206/206 [==============================] - 70s 330ms/step - loss: 1.1279 - accuracy: 0.5706 - val_loss: 1.4316 - val_accuracy: 0.4744\n",
            "Epoch 4/50\n",
            "206/206 [==============================] - 69s 329ms/step - loss: 1.0832 - accuracy: 0.5868 - val_loss: 1.5064 - val_accuracy: 0.4444\n",
            "Epoch 5/50\n",
            "206/206 [==============================] - 70s 330ms/step - loss: 1.0046 - accuracy: 0.6204 - val_loss: 1.5029 - val_accuracy: 0.4774\n",
            "Epoch 6/50\n",
            "206/206 [==============================] - 69s 328ms/step - loss: 0.9332 - accuracy: 0.6420 - val_loss: 1.5053 - val_accuracy: 0.4615\n",
            "Epoch 7/50\n",
            "206/206 [==============================] - 69s 329ms/step - loss: 0.8753 - accuracy: 0.6625 - val_loss: 1.4715 - val_accuracy: 0.4829\n",
            "Epoch 8/50\n",
            "206/206 [==============================] - 70s 330ms/step - loss: 0.8175 - accuracy: 0.6893 - val_loss: 1.4626 - val_accuracy: 0.4835\n",
            "Epoch 9/50\n",
            "206/206 [==============================] - 70s 333ms/step - loss: 0.7884 - accuracy: 0.6972 - val_loss: 1.4906 - val_accuracy: 0.4731\n",
            "Epoch 10/50\n",
            "206/206 [==============================] - 70s 333ms/step - loss: 0.6965 - accuracy: 0.7332 - val_loss: 1.6406 - val_accuracy: 0.4377\n",
            "Epoch 11/50\n",
            "206/206 [==============================] - 70s 332ms/step - loss: 0.6429 - accuracy: 0.7577 - val_loss: 1.7561 - val_accuracy: 0.4512\n",
            "Epoch 12/50\n",
            "206/206 [==============================] - 70s 333ms/step - loss: 0.5666 - accuracy: 0.7927 - val_loss: 1.7284 - val_accuracy: 0.4457\n",
            "Epoch 13/50\n",
            "206/206 [==============================] - 70s 333ms/step - loss: 0.5062 - accuracy: 0.8183 - val_loss: 1.8653 - val_accuracy: 0.4316\n",
            "Epoch 14/50\n",
            "206/206 [==============================] - 70s 333ms/step - loss: 0.4644 - accuracy: 0.8344 - val_loss: 1.8660 - val_accuracy: 0.4621\n",
            "Epoch 15/50\n",
            "206/206 [==============================] - 70s 332ms/step - loss: 0.4399 - accuracy: 0.8440 - val_loss: 2.2578 - val_accuracy: 0.3993\n",
            "Epoch 16/50\n",
            "206/206 [==============================] - 70s 334ms/step - loss: 0.3634 - accuracy: 0.8765 - val_loss: 2.2187 - val_accuracy: 0.4237\n",
            "Epoch 17/50\n",
            "206/206 [==============================] - 70s 334ms/step - loss: 0.2944 - accuracy: 0.9066 - val_loss: 2.1312 - val_accuracy: 0.4347\n",
            "Epoch 18/50\n",
            "206/206 [==============================] - 70s 333ms/step - loss: 0.2576 - accuracy: 0.9165 - val_loss: 2.2579 - val_accuracy: 0.4176\n",
            "Epoch 19/50\n",
            "206/206 [==============================] - 70s 334ms/step - loss: 0.2181 - accuracy: 0.9332 - val_loss: 2.4477 - val_accuracy: 0.4182\n",
            "Epoch 20/50\n",
            "206/206 [==============================] - 70s 332ms/step - loss: 0.1978 - accuracy: 0.9424 - val_loss: 2.3753 - val_accuracy: 0.4335\n",
            "Epoch 21/50\n",
            "206/206 [==============================] - 70s 332ms/step - loss: 0.1673 - accuracy: 0.9532 - val_loss: 2.4819 - val_accuracy: 0.4359\n",
            "Epoch 22/50\n",
            "206/206 [==============================] - 70s 331ms/step - loss: 0.1721 - accuracy: 0.9504 - val_loss: 2.3945 - val_accuracy: 0.4658\n",
            "Epoch 23/50\n",
            "206/206 [==============================] - 70s 331ms/step - loss: 0.1546 - accuracy: 0.9542 - val_loss: 2.7401 - val_accuracy: 0.4200\n",
            "Epoch 24/50\n",
            "206/206 [==============================] - 70s 331ms/step - loss: 0.1416 - accuracy: 0.9595 - val_loss: 2.7857 - val_accuracy: 0.4444\n",
            "Epoch 25/50\n",
            "206/206 [==============================] - 70s 330ms/step - loss: 0.1069 - accuracy: 0.9717 - val_loss: 2.8739 - val_accuracy: 0.4164\n",
            "Epoch 26/50\n",
            "206/206 [==============================] - 70s 331ms/step - loss: 0.0858 - accuracy: 0.9795 - val_loss: 3.1922 - val_accuracy: 0.4206\n",
            "Epoch 27/50\n",
            "206/206 [==============================] - 70s 331ms/step - loss: 0.0942 - accuracy: 0.9761 - val_loss: 3.2699 - val_accuracy: 0.4158\n",
            "Epoch 28/50\n",
            "206/206 [==============================] - 70s 332ms/step - loss: 0.0853 - accuracy: 0.9796 - val_loss: 3.2533 - val_accuracy: 0.4182\n",
            "Epoch 29/50\n",
            "206/206 [==============================] - 70s 331ms/step - loss: 0.0689 - accuracy: 0.9848 - val_loss: 3.2733 - val_accuracy: 0.4127\n",
            "Epoch 30/50\n",
            "206/206 [==============================] - 71s 335ms/step - loss: 0.1582 - accuracy: 0.9465 - val_loss: 3.0389 - val_accuracy: 0.4170\n",
            "Epoch 31/50\n",
            "206/206 [==============================] - 70s 332ms/step - loss: 0.0780 - accuracy: 0.9802 - val_loss: 3.1825 - val_accuracy: 0.4328\n",
            "Epoch 32/50\n",
            "206/206 [==============================] - 70s 331ms/step - loss: 0.0589 - accuracy: 0.9854 - val_loss: 3.4837 - val_accuracy: 0.4261\n",
            "Epoch 33/50\n",
            "206/206 [==============================] - 70s 332ms/step - loss: 0.0426 - accuracy: 0.9919 - val_loss: 3.5609 - val_accuracy: 0.4170\n",
            "Epoch 34/50\n",
            "206/206 [==============================] - 70s 333ms/step - loss: 0.0608 - accuracy: 0.9840 - val_loss: 3.2862 - val_accuracy: 0.4426\n",
            "Epoch 35/50\n",
            "206/206 [==============================] - 70s 332ms/step - loss: 0.0452 - accuracy: 0.9903 - val_loss: 3.6704 - val_accuracy: 0.4164\n",
            "Epoch 36/50\n",
            "206/206 [==============================] - 70s 330ms/step - loss: 0.1037 - accuracy: 0.9652 - val_loss: 3.4482 - val_accuracy: 0.4322\n",
            "Epoch 37/50\n",
            "206/206 [==============================] - 70s 330ms/step - loss: 0.0560 - accuracy: 0.9854 - val_loss: 3.5889 - val_accuracy: 0.4255\n",
            "Epoch 38/50\n",
            "206/206 [==============================] - 69s 328ms/step - loss: 0.0667 - accuracy: 0.9808 - val_loss: 3.9039 - val_accuracy: 0.4255\n",
            "Epoch 39/50\n",
            "206/206 [==============================] - 69s 329ms/step - loss: 0.0982 - accuracy: 0.9656 - val_loss: 4.0848 - val_accuracy: 0.4274\n",
            "Epoch 40/50\n",
            "206/206 [==============================] - 70s 331ms/step - loss: 0.1359 - accuracy: 0.9492 - val_loss: 3.4431 - val_accuracy: 0.4396\n",
            "Epoch 41/50\n",
            "206/206 [==============================] - 70s 329ms/step - loss: 0.0652 - accuracy: 0.9793 - val_loss: 4.0686 - val_accuracy: 0.4121\n",
            "Epoch 42/50\n",
            "206/206 [==============================] - 70s 330ms/step - loss: 0.0535 - accuracy: 0.9831 - val_loss: 4.1714 - val_accuracy: 0.4225\n",
            "Epoch 43/50\n",
            "206/206 [==============================] - 70s 330ms/step - loss: 0.0399 - accuracy: 0.9890 - val_loss: 3.9518 - val_accuracy: 0.4310\n",
            "Epoch 44/50\n",
            "206/206 [==============================] - 70s 331ms/step - loss: 0.0325 - accuracy: 0.9929 - val_loss: 4.2005 - val_accuracy: 0.4170\n",
            "Epoch 45/50\n",
            "206/206 [==============================] - 69s 329ms/step - loss: 0.0705 - accuracy: 0.9775 - val_loss: 3.9473 - val_accuracy: 0.4335\n",
            "Epoch 46/50\n",
            "206/206 [==============================] - 69s 329ms/step - loss: 0.0922 - accuracy: 0.9662 - val_loss: 4.5284 - val_accuracy: 0.3785\n",
            "Epoch 47/50\n",
            "206/206 [==============================] - 70s 332ms/step - loss: 0.0757 - accuracy: 0.9738 - val_loss: 4.3397 - val_accuracy: 0.4231\n",
            "Epoch 48/50\n",
            "206/206 [==============================] - 69s 329ms/step - loss: 0.0379 - accuracy: 0.9881 - val_loss: 4.2676 - val_accuracy: 0.4389\n",
            "Epoch 49/50\n",
            "206/206 [==============================] - 70s 330ms/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 4.2186 - val_accuracy: 0.4304\n",
            "Epoch 50/50\n",
            "206/206 [==============================] - 70s 331ms/step - loss: 0.0254 - accuracy: 0.9954 - val_loss: 4.6041 - val_accuracy: 0.4084\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f714d233290>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y8oYwONLCYR",
        "outputId": "b1d0f1ac-57ab-4683-d151-5d44c67df98f"
      },
      "source": [
        "from keras.models import load_model\n",
        "model3.save('model-for-female.h5')\n",
        "model4.save('model-for-male.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        }
      ]
    }
  ]
}